{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-23T02:57:11.907485Z","iopub.execute_input":"2023-02-23T02:57:11.908117Z","iopub.status.idle":"2023-02-23T02:57:11.947390Z","shell.execute_reply.started":"2023-02-23T02:57:11.907944Z","shell.execute_reply":"2023-02-23T02:57:11.945911Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/utils-nmr/utils_nmr.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install halo tqdm pathlib numerapi --quiet","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:57:20.586950Z","iopub.execute_input":"2023-02-23T02:57:20.587406Z","iopub.status.idle":"2023-02-23T02:57:38.205349Z","shell.execute_reply.started":"2023-02-23T02:57:20.587371Z","shell.execute_reply":"2023-02-23T02:57:38.203904Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"utils_path = '/kaggle/input/utils-nmr'\nimport sys\nsys.path.insert(1, utils_path)\n\nimport utils_nmr","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:58:08.857004Z","iopub.execute_input":"2023-02-23T02:58:08.857426Z","iopub.status.idle":"2023-02-23T02:58:09.158359Z","shell.execute_reply.started":"2023-02-23T02:58:08.857393Z","shell.execute_reply":"2023-02-23T02:58:09.157112Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nimport gc\nimport json\nfrom pathlib import Path\n\nfrom numerapi import NumerAPI\nfrom utils_nmr import (\n    save_model,\n    load_model,\n    neutralize,\n    get_biggest_change_features,\n    validation_metrics,\n    ERA_COL,\n    DATA_TYPE_COL,\n    TARGET_COL,\n    EXAMPLE_PREDS_COL\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:58:16.907514Z","iopub.execute_input":"2023-02-23T02:58:16.908202Z","iopub.status.idle":"2023-02-23T02:58:18.301718Z","shell.execute_reply.started":"2023-02-23T02:58:16.908160Z","shell.execute_reply":"2023-02-23T02:58:18.300426Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"napi = NumerAPI()\n\ncurrent_round = napi.get_current_round()\n\nprint('Downloading dataset files...')\n\nPath(\"./v4\").mkdir(parents=False, exist_ok=True)\nnapi.download_dataset(\"v4/train.parquet\")\nnapi.download_dataset(\"v4/validation.parquet\")\nnapi.download_dataset(\"v4/live.parquet\", f\"v4/live_{current_round}.parquet\")\nnapi.download_dataset(\"v4/validation_example_preds.parquet\")\nnapi.download_dataset(\"v4/features.json\")","metadata":{"execution":{"iopub.status.busy":"2023-02-23T02:58:29.016630Z","iopub.execute_input":"2023-02-23T02:58:29.017063Z","iopub.status.idle":"2023-02-23T03:00:56.026117Z","shell.execute_reply.started":"2023-02-23T02:58:29.017015Z","shell.execute_reply":"2023-02-23T03:00:56.024991Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading dataset files...\n","output_type":"stream"},{"name":"stderr","text":"v4/train.parquet: 1.15GB [01:05, 17.5MB/s]                             \nv4/validation.parquet: 1.16GB [00:59, 19.6MB/s]                             \nv4/live_426.parquet: 3.41MB [00:00, 3.67MB/s]                            \nv4/validation_example_preds.parquet: 57.4MB [00:12, 4.49MB/s]                            \nv4/features.json: 562kB [00:00, 1.06MB/s]                           \n","output_type":"stream"},{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"print('Reading minimal training data')\n# read the feature metadata and get a feature set (or all the features)\nwith open(\"v4/features.json\", \"r\") as f:\n    feature_metadata = json.load(f)\n# features = list(feature_metadata[\"feature_stats\"].keys()) # get all the features\n# features = feature_metadata[\"feature_sets\"][\"small\"] # get the small feature set\nfeatures = feature_metadata[\"feature_sets\"][\"medium\"] # get the medium feature set\n# read in just those features along with era and target columns\nread_columns = features + [ERA_COL, DATA_TYPE_COL, TARGET_COL]","metadata":{"execution":{"iopub.status.busy":"2023-02-23T03:01:08.847662Z","iopub.execute_input":"2023-02-23T03:01:08.848108Z","iopub.status.idle":"2023-02-23T03:01:08.867340Z","shell.execute_reply.started":"2023-02-23T03:01:08.848070Z","shell.execute_reply":"2023-02-23T03:01:08.865878Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Reading minimal training data\n\r","output_type":"stream"}]},{"cell_type":"code","source":"feature_metadata[\"feature_sets\"].keys()\nprint(len(features))","metadata":{"execution":{"iopub.status.busy":"2023-02-23T03:01:37.597324Z","iopub.execute_input":"2023-02-23T03:01:37.597866Z","iopub.status.idle":"2023-02-23T03:01:37.608258Z","shell.execute_reply.started":"2023-02-23T03:01:37.597820Z","shell.execute_reply":"2023-02-23T03:01:37.606657Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"472\n\r","output_type":"stream"}]},{"cell_type":"code","source":"# note: sometimes when trying to read the downloaded data you get an error about invalid magic parquet bytes...\n# if so, delete the file and rerun the napi.download_dataset to fix the corrupted file\ntraining_data = pd.read_parquet('v4/train.parquet',\n                                columns=read_columns)\nvalidation_data = pd.read_parquet('v4/validation.parquet',\n                                  columns=read_columns)\nlive_data = pd.read_parquet(f'v4/live_{current_round}.parquet',\n                                  columns=read_columns)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T03:01:51.317929Z","iopub.execute_input":"2023-02-23T03:01:51.318433Z","iopub.status.idle":"2023-02-23T03:02:24.003223Z","shell.execute_reply.started":"2023-02-23T03:01:51.318395Z","shell.execute_reply":"2023-02-23T03:02:24.001099Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"# pare down the number of eras to every 4th era\n# every_4th_era = training_data[ERA_COL].unique()[::4]\n# training_data = training_data[training_data[ERA_COL].isin(every_4th_era)]\n\n# getting the per era correlation of each feature vs the target\nall_feature_corrs = training_data.groupby(ERA_COL).apply(\n    lambda era: era[features].corrwith(era[TARGET_COL])\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T03:02:37.938581Z","iopub.execute_input":"2023-02-23T03:02:37.939097Z","iopub.status.idle":"2023-02-23T03:04:28.002662Z","shell.execute_reply.started":"2023-02-23T03:02:37.939061Z","shell.execute_reply":"2023-02-23T03:04:28.001269Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"# find the riskiest features by comparing their correlation vs\n# the target in each half of training data; we'll use these later\nriskiest_features = get_biggest_change_features(all_feature_corrs, 50)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T03:04:53.897056Z","iopub.execute_input":"2023-02-23T03:04:53.897513Z","iopub.status.idle":"2023-02-23T03:04:53.915376Z","shell.execute_reply.started":"2023-02-23T03:04:53.897476Z","shell.execute_reply":"2023-02-23T03:04:53.914214Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"# \"garbage collection\" (gc) gets rid of unused data and frees up memory\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T03:04:57.225829Z","iopub.execute_input":"2023-02-23T03:04:57.226230Z","iopub.status.idle":"2023-02-23T03:04:57.466545Z","shell.execute_reply.started":"2023-02-23T03:04:57.226199Z","shell.execute_reply":"2023-02-23T03:04:57.465597Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"6946"},"metadata":{}},{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"model_name = f\"model_target\"\nprint(f\"Checking for existing model '{model_name}'\")\nmodel = load_model(model_name)\nif not model:\n    print(f\"model not found, creating new one\")\n    params = {\"n_estimators\": 2000,\n              \"learning_rate\": 0.01,\n              \"max_depth\": 5,\n              \"num_leaves\": 2 ** 5,\n              \"colsample_bytree\": 0.1}\n\n    model = LGBMRegressor(**params)\n\n    # train on all of train and save the model so we don't have to train next time\n    model.fit(training_data.filter(like='feature_', axis='columns'),\n              training_data[TARGET_COL])\n    print(f\"saving new model: {model_name}\")\n    save_model(model, model_name)\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T03:05:06.466254Z","iopub.execute_input":"2023-02-23T03:05:06.466714Z","iopub.status.idle":"2023-02-23T03:22:56.205070Z","shell.execute_reply.started":"2023-02-23T03:05:06.466667Z","shell.execute_reply":"2023-02-23T03:22:56.203799Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Checking for existing model 'model_target'\nmodel not found, creating new one\nsaving new model: model_target\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"48"},"metadata":{}},{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"nans_per_col = live_data[live_data[\"data_type\"] == \"live\"][features].isna().sum()\n\n# check for nans and fill nans\nif nans_per_col.any():\n    total_rows = len(live_data[live_data[\"data_type\"] == \"live\"])\n    print(f\"Number of nans per column this week: {nans_per_col[nans_per_col > 0]}\")\n    print(f\"out of {total_rows} total rows\")\n    print(f\"filling nans with 0.5\")\n    live_data.loc[:, features] = live_data.loc[:, features].fillna(0.5)\n\nelse:\n    print(\"No nans in the features this week!\")","metadata":{"execution":{"iopub.status.busy":"2023-02-23T03:31:45.717148Z","iopub.execute_input":"2023-02-23T03:31:45.718590Z","iopub.status.idle":"2023-02-23T03:31:45.764674Z","shell.execute_reply.started":"2023-02-23T03:31:45.718529Z","shell.execute_reply":"2023-02-23T03:31:45.763476Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"No nans in the features this week!\n\r","output_type":"stream"}]},{"cell_type":"code","source":"# double check the feature that the model expects vs what is available to prevent our\n# pipeline from failing if Numerai adds more data and we don't have time to retrain!\nmodel_expected_features = model.booster_.feature_name()\nif set(model_expected_features) != set(features):\n    print(f\"New features are available! Might want to retrain model {model_name}.\")\nvalidation_data.loc[:, f\"preds_{model_name}\"] = model.predict(\n    validation_data.loc[:, model_expected_features])\nlive_data.loc[:, f\"preds_{model_name}\"] = model.predict(\n    live_data.loc[:, model_expected_features])\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-02-23T03:31:54.817720Z","iopub.execute_input":"2023-02-23T03:31:54.818716Z","iopub.status.idle":"2023-02-23T03:35:24.792168Z","shell.execute_reply.started":"2023-02-23T03:31:54.818671Z","shell.execute_reply":"2023-02-23T03:35:24.791043Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}},{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"# neutralize our predictions to the riskiest features\nvalidation_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(\n    df=validation_data,\n    columns=[f\"preds_{model_name}\"],\n    neutralizers=riskiest_features,\n    proportion=1.0,\n    normalize=True,\n    era_col=ERA_COL\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:10:24.565701Z","iopub.execute_input":"2023-02-23T04:10:24.566237Z","iopub.status.idle":"2023-02-23T04:12:57.957346Z","shell.execute_reply.started":"2023-02-23T04:10:24.566196Z","shell.execute_reply":"2023-02-23T04:12:57.953861Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"live_data[f\"preds_{model_name}_neutral_riskiest_50\"] = neutralize(\n    df=live_data,\n    columns=[f\"preds_{model_name}\"],\n    neutralizers=riskiest_features,\n    proportion=1.0,\n    normalize=True,\n    era_col=ERA_COL\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:13:49.244723Z","iopub.execute_input":"2023-02-23T04:13:49.245231Z","iopub.status.idle":"2023-02-23T04:13:49.336157Z","shell.execute_reply.started":"2023-02-23T04:13:49.245189Z","shell.execute_reply":"2023-02-23T04:13:49.334174Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"model_to_submit = f\"preds_{model_name}_neutral_riskiest_50\"","metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:13:59.505369Z","iopub.execute_input":"2023-02-23T04:13:59.505792Z","iopub.status.idle":"2023-02-23T04:13:59.513180Z","shell.execute_reply.started":"2023-02-23T04:13:59.505759Z","shell.execute_reply":"2023-02-23T04:13:59.511606Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"# rename best model to \"prediction\" and rank from 0 to 1 to meet upload requirements\nvalidation_data[\"prediction\"] = validation_data[model_to_submit].rank(pct=True)\nlive_data[\"prediction\"] = live_data[model_to_submit].rank(pct=True)\nvalidation_data[\"prediction\"].to_csv(f\"validation_predictions_{current_round}.csv\")\nlive_data[\"prediction\"].to_csv(f\"live_predictions_{current_round}.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:14:03.633572Z","iopub.execute_input":"2023-02-23T04:14:03.634928Z","iopub.status.idle":"2023-02-23T04:14:09.273139Z","shell.execute_reply.started":"2023-02-23T04:14:03.634874Z","shell.execute_reply":"2023-02-23T04:14:09.271712Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"validation_preds = pd.read_parquet('v4/validation_example_preds.parquet')\nvalidation_data[EXAMPLE_PREDS_COL] = validation_preds[\"prediction\"]","metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:14:14.053773Z","iopub.execute_input":"2023-02-23T04:14:14.054215Z","iopub.status.idle":"2023-02-23T04:14:16.241128Z","shell.execute_reply.started":"2023-02-23T04:14:14.054176Z","shell.execute_reply":"2023-02-23T04:14:16.240002Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\r","output_type":"stream"}]},{"cell_type":"code","source":"# get some stats about each of our models to compare...\n# fast_mode=True so that we skip some of the stats that are slower to calculate\nvalidation_stats = validation_metrics(validation_data, [model_to_submit, f\"preds_{model_name}\"], example_col=EXAMPLE_PREDS_COL, fast_mode=True, target_col=TARGET_COL)\nprint(validation_stats[[\"mean\", \"sharpe\"]].to_markdown())","metadata":{"execution":{"iopub.status.busy":"2023-02-23T04:14:20.684002Z","iopub.execute_input":"2023-02-23T04:14:20.684738Z","iopub.status.idle":"2023-02-23T04:21:35.068444Z","shell.execute_reply.started":"2023-02-23T04:14:20.684688Z","shell.execute_reply":"2023-02-23T04:21:35.067265Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"|                                        |      mean |   sharpe |\n|:---------------------------------------|----------:|---------:|\n| preds_model_target_neutral_riskiest_50 | 0.0262633 | 0.973428 |\n| preds_model_target                     | 0.0269323 | 0.858913 |\n\r","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}